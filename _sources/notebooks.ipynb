{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Програма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ox-mC9UTPk9"
   },
   "source": [
    "Описот на целосната постапка е вклучен во Jupyter книгата, па коментари околу кодот во Notebook-от се одлучивме да не вклучуваме."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2kY5CYcO4k0C"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "I58hL1D64796"
   },
   "outputs": [],
   "source": [
    "def extract_index_nparray(nparray):\n",
    "    index = None\n",
    "\n",
    "    for num in nparray[0]:\n",
    "        index = num\n",
    "        break\n",
    "\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3-hgEeg64-FZ"
   },
   "outputs": [],
   "source": [
    "img1 = cv2.imread(\"media/736px-Josip_Broz_Tito_uniform_portrait.jpg\")\n",
    "img2 = cv2.imread(\"media/768px-Queen_Elizabeth_II_of_New_Zealand_(cropped).jpg\")\n",
    "\n",
    "img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "mask = np.zeros_like(img1_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "56wLcaNj5UTb",
    "outputId": "c7ae585e-994d-4aa7-eecf-a80b657777d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-07-05 01:49:37--  https://github.com/JeffTrain/selfie/raw/master/shape_predictor_68_face_landmarks.dat\n",
      "Loaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\n",
      "Resolving github.com (github.com)... 140.82.121.4\n",
      "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/JeffTrain/selfie/master/shape_predictor_68_face_landmarks.dat [following]\n",
      "--2021-07-05 01:49:37--  https://raw.githubusercontent.com/JeffTrain/selfie/master/shape_predictor_68_face_landmarks.dat\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 99693937 (95M) [application/octet-stream]\n",
      "Saving to: 'shape_predictor_68_face_landmarks.dat'\n",
      "\n",
      "shape_predictor_68_ 100%[===================>]  95.08M  4.85MB/s    in 19s     \n",
      "\n",
      "2021-07-05 01:50:00 (4.92 MB/s) - 'shape_predictor_68_face_landmarks.dat' saved [99693937/99693937]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -nd https://github.com/JeffTrain/selfie/raw/master/shape_predictor_68_face_landmarks.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "8mYdQr5c5CiR"
   },
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "xa1c-5ti5m3J"
   },
   "outputs": [],
   "source": [
    "faces = detector(img1_gray)\n",
    "for face in faces:\n",
    "    landmarks = predictor(img1_gray, face)\n",
    "    landmarks_points1 = []\n",
    "    for n in range(0, 68):\n",
    "        x = landmarks.part(n).x\n",
    "        y = landmarks.part(n).y\n",
    "        landmarks_points1.append((x, y))\n",
    "\n",
    "    points = np.array(landmarks_points1, np.int32)\n",
    "    convexhull = cv2.convexHull(points)\n",
    "    cv2.fillConvexPoly(mask, convexhull, 255)\n",
    "\n",
    "    rect = cv2.boundingRect(convexhull)\n",
    "    subdiv = cv2.Subdiv2D(rect)\n",
    "    subdiv.insert(landmarks_points1)\n",
    "    triangles = subdiv.getTriangleList()\n",
    "    triangles = np.array(triangles, dtype=np.int32)\n",
    "\n",
    "    indexes_triangles = []\n",
    "    for t in triangles:\n",
    "        pt1 = t[0], t[1]\n",
    "        pt2 = t[2], t[3]\n",
    "        pt3 = t[4], t[5]\n",
    "\n",
    "        index_pt1 = np.where((points == pt1).all(axis=1))\n",
    "        index_pt1 = extract_index_nparray(index_pt1)\n",
    "\n",
    "        index_pt2 = np.where((points == pt2).all(axis=1))\n",
    "        index_pt2 = extract_index_nparray(index_pt2)\n",
    "\n",
    "        index_pt3 = np.where((points == pt3).all(axis=1))\n",
    "        index_pt3 = extract_index_nparray(index_pt3)\n",
    "\n",
    "        if index_pt1 is not None and index_pt2 is not None and index_pt3 is not None:\n",
    "            triangle = [index_pt1, index_pt2, index_pt3]\n",
    "            indexes_triangles.append(triangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "HEd38qRe5oVp"
   },
   "outputs": [],
   "source": [
    "faces2 = detector(img2_gray)\n",
    "for face in faces2:\n",
    "    landmarks = predictor(img2_gray, face)\n",
    "    landmarks_points2 = []\n",
    "    for n in range(0, 68):\n",
    "        x = landmarks.part(n).x\n",
    "        y = landmarks.part(n).y\n",
    "        landmarks_points2.append((x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "s768Oo0f5uaU"
   },
   "outputs": [],
   "source": [
    "img2_new_face = np.zeros((1024, 768, 3), np.uint8)\n",
    "\n",
    "for triangle_index in indexes_triangles:\n",
    "    pt1_1 = landmarks_points1[triangle_index[0]]\n",
    "    pt2_1 = landmarks_points1[triangle_index[1]]\n",
    "    pt3_1 = landmarks_points1[triangle_index[2]]\n",
    "\n",
    "    tr1 = np.array([pt1_1, pt2_1, pt3_1], np.int32)\n",
    "    rect1 = cv2.boundingRect(tr1)\n",
    "    x, y, w, h = rect1\n",
    "    cropped_triangle1 = img1[y: y + h, x: x + w]\n",
    "    cropped_tr1_mask = np.zeros((h, w), np.uint8)\n",
    "\n",
    "    points1 = np.array([[pt1_1[0] - x, pt1_1[1] - y], [pt2_1[0] - x, pt2_1[1] - y], [pt3_1[0] - x, pt3_1[1] - y]],\n",
    "                       np.int32)\n",
    "    cv2.fillConvexPoly(cropped_tr1_mask, points1, 255)\n",
    "    cropped_triangle1 = cv2.bitwise_and(cropped_triangle1, cropped_triangle1, mask=cropped_tr1_mask)\n",
    "\n",
    "    pt1_2 = landmarks_points2[triangle_index[0]]\n",
    "    pt2_2 = landmarks_points2[triangle_index[1]]\n",
    "    pt3_2 = landmarks_points2[triangle_index[2]]\n",
    "\n",
    "    tr2 = np.array([pt1_2, pt2_2, pt3_2], np.int32)\n",
    "    rect2 = cv2.boundingRect(tr2)\n",
    "    x, y, w, h = rect2\n",
    "    cropped_triangle2 = img2[y: y + h, x: x + w]\n",
    "    cropped_tr2_mask = np.zeros((h, w), np.uint8)\n",
    "\n",
    "    points2 = np.array([[pt1_2[0] - x, pt1_2[1] - y], [pt2_2[0] - x, pt2_2[1] - y], [pt3_2[0] - x, pt3_2[1] - y]],\n",
    "                       np.int32)\n",
    "    cv2.fillConvexPoly(cropped_tr2_mask, points2, 255)\n",
    "    cropped_triangle2 = cv2.bitwise_and(cropped_triangle2, cropped_triangle2, mask=cropped_tr2_mask)\n",
    "\n",
    "    points1 = np.float32(points1)\n",
    "    points2 = np.float32(points2)\n",
    "\n",
    "    M = cv2.getAffineTransform(points1, points2)\n",
    "\n",
    "    warped_triangle = cv2.warpAffine(cropped_triangle1, M, (w, h))\n",
    "    warped_triangle = cv2.bitwise_and(warped_triangle, warped_triangle, mask=cropped_tr2_mask)\n",
    "\n",
    "    img2_new_face_rect_area = img2_new_face[y: y + h, x: x + w]\n",
    "    img2_new_face_rect_area_gray = cv2.cvtColor(img2_new_face_rect_area, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # _, mask_triangles_designed = cv2.threshold(img2_new_face_rect_area_gray, 64, 255, cv2.THRESH_BINARY_INV)\n",
    "    # warped_triangle = cv2.bitwise_and(warped_triangle, warped_triangle, mask=mask_triangles_designed)\n",
    "\n",
    "    img2_new_face_rect_area = cv2.add(img2_new_face_rect_area, warped_triangle)\n",
    "    img2_new_face[y: y + h, x: x + w] = img2_new_face_rect_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "CwucbhNJ5w6Z"
   },
   "outputs": [],
   "source": [
    "convexhull2 = cv2.convexHull(np.array(landmarks_points2, np.int32))\n",
    "img2_face_mask = np.zeros_like(img2_gray)\n",
    "img2_head_mask = cv2.fillConvexPoly(img2_face_mask, convexhull2, 255)\n",
    "\n",
    "img2_face_mask = cv2.bitwise_not(img2_head_mask)\n",
    "img2_head_noface = cv2.bitwise_and(img2, img2, mask=img2_face_mask)\n",
    "\n",
    "result = cv2.add(img2_head_noface, img2_new_face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "c2jbOmSN50ES"
   },
   "outputs": [],
   "source": [
    "x, y, w, h = cv2.boundingRect(convexhull2)\n",
    "center_face2 = int((x + x + w) / 2), int((y + y + h) / 2)\n",
    "seamlessclone = cv2.seamlessClone(result, img2, img2_head_mask, center_face2, cv2.MIXED_CLONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "LwmUz0Yw57MG",
    "outputId": "9b90d11e-32fb-4a50-9166-7410d0c77cce"
   },
   "outputs": [],
   "source": [
    "cv2.imshow(\"End result\", seamlessclone)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "face_swapping_code.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "face-recognition-project",
   "language": "python",
   "name": "face-recognition-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
